{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb3b4d1-03cd-4568-abfb-6d81d73dc7fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a810d1e1a7c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mDCGANOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "# DCGAN\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname == 'ConvTranspose2d' or classname == 'Conv2d':\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname == 'BatchNorm2d':\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, conv_kwargs, activation='leaky_relu', normalization='batch_normalization'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(**conv_kwargs)\n",
    "        \n",
    "        if normalization == 'batch_normalization': self.norm = nn.BatchNorm2d(conv_kwargs['out_channels'])\n",
    "        elif normalization == 'instance_normalization': self.norm = nn.InstanceNorm2d(conv_kwargs['out_channels'])\n",
    "        elif normalization is None: self.norm = nn.Sequential()\n",
    "        \n",
    "        if activation == 'leaky_relu': self.actv = nn.LeakyReLU(0.2)\n",
    "        elif activation == 'sigmoid': self.actv = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        out = self.actv(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "        depth = int(math.log2(args.resolution)) -1\n",
    "\n",
    "        net = [ConvBlock(\n",
    "            {\n",
    "                'in_channels': args.nc,\n",
    "                'out_channels': args.ngf,\n",
    "                'kernel_size': 4,\n",
    "                'stride': 2,\n",
    "                'padding': 1\n",
    "            },\n",
    "            normalization=None\n",
    "        )]\n",
    "        \n",
    "        mult = 1\n",
    "        for _ in range(depth - 2):\n",
    "            net.append(ConvBlock(\n",
    "                {\n",
    "                    'in_channels': args.ngf * mult,\n",
    "                    'out_channels': args.ngf * mult * 2,\n",
    "                    'kernel_size': 4,\n",
    "                    'stride': 2,\n",
    "                    'padding': 1\n",
    "                }\n",
    "            ))\n",
    "            mult *= 2\n",
    "        net.append(ConvBlock(\n",
    "            {\n",
    "                'in_channels': args.ngf * mult,\n",
    "                'out_channels': 1,\n",
    "                'kernel_size': 4,\n",
    "                'stride': 1,\n",
    "                'padding': 0\n",
    "            },\n",
    "            activation='sigmoid',\n",
    "            normalization=None\n",
    "        ))\n",
    "        self.net = nn.Sequential(*net)\n",
    "        self.apply(weights_init)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "\n",
    "class ConvTransposeBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, deconv_kwargs, activation='relu', normalization='batch_normalization'):\n",
    "        super(ConvTransposeBlock, self).__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(**deconv_kwargs)\n",
    "        \n",
    "        if normalization == 'batch_normalization': self.norm = nn.BatchNorm2d(deconv_kwargs['out_channels'])\n",
    "        elif normalization == 'instance_normalization': self.norm = nn.InstanceNorm2d(deconv_kwargs['out_channels'])\n",
    "        elif normalization is None: self.norm = nn.Sequential()\n",
    "        \n",
    "        if activation == 'relu': self.actv = nn.ReLU()\n",
    "        elif activation == 'tanh': self.actv = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.deconv(x)\n",
    "        out = self.norm(out)\n",
    "        out = self.actv(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "class DCGANGenerator(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(DCGANGenerator, self).__init__()\n",
    "        depth = int(math.log2(args.resolution)) -1\n",
    "        \n",
    "        mult = 2 ** (depth - 2)\n",
    "        net = [ConvTransposeBlock(\n",
    "            {\n",
    "                'in_channels': args.nz,\n",
    "                'out_channels': args.ngf * mult,\n",
    "                'kernel_size': 4,\n",
    "                'stride': 1,\n",
    "                'padding': 0\n",
    "            },\n",
    "        )]\n",
    "        for _ in range(depth - 2):\n",
    "            mult = int(mult * 0.5)\n",
    "            net.append(ConvTransposeBlock(\n",
    "                {\n",
    "                    'in_channels': args.ngf * mult * 2,\n",
    "                    'out_channels': args.ngf * mult,\n",
    "                    'kernel_size': 4,\n",
    "                    'stride': 2,\n",
    "                    'padding': 1\n",
    "                },\n",
    "            ))\n",
    "        net.append(ConvTransposeBlock(\n",
    "            {\n",
    "                'in_channels': args.ngf * mult,\n",
    "                'out_channels': args.nc,\n",
    "                'kernel_size': 4,\n",
    "                'stride': 2,\n",
    "                'padding': 1\n",
    "            },\n",
    "            activation='tanh',\n",
    "            normalization=None\n",
    "        ))\n",
    "        \n",
    "        self.net = nn.Sequential(*net)\n",
    "        self.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class DCGANLoss(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(DCGANLoss, self).__init__()\n",
    "        self.device = args.device\n",
    "        self.bce = nn.BCELoss()\n",
    "        \n",
    "    def forward(self, x, mode='discriminator_loss'):\n",
    "        if mode == 'discriminator_loss':\n",
    "            fake_pred, real_pred = x\n",
    "            real_loss = self.bce(real_pred, torch.tensor(1.0).expand_as(real_pred).to(self.device))\n",
    "            fake_loss = self.bce(fake_pred, torch.tensor(0.0).expand_as(fake_pred).to(self.device))\n",
    "            loss = (real_loss + fake_loss) * 0.5\n",
    "            \n",
    "        elif mode == 'generator_loss':\n",
    "            fake_pred, _ = x\n",
    "            loss = self.bce(fake_pred, torch.tensor(1.0).expand_as(fake_pred).to(self.device))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "class DCGANOptimizer(optim.Adam):\n",
    "    def __init__(self, args, params):\n",
    "        self.args = args\n",
    "        self.params = params\n",
    "        \n",
    "        super(DCGANOptimizer, self).__init__(\n",
    "            params,\n",
    "            lr=args.lr,\n",
    "        )\n",
    "\n",
    "    def step(self):\n",
    "        loss = super(DCGANOptimizer, self).step()\n",
    "        return loss\n",
    "\n",
    "components = {\n",
    "    'generator': DCGANGenerator,\n",
    "    'discriminator': DCGANDiscriminator,\n",
    "    'criterion': DCGANLoss,\n",
    "    'optimizer': DCGANOptimizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d111c6a6-0e4b-413b-8a88-53960ddf6b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9743)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "args = EasyDict({\n",
    "    'resolution': 32,\n",
    "    'nz': 100,\n",
    "    'ngf': 64,\n",
    "    'ndf': 64,\n",
    "    'nc': 3,\n",
    "    'device': 'cpu'\n",
    "})\n",
    "g = DCGANGenerator(args)\n",
    "g(torch.rand(1, 100, 1, 1))\n",
    "# d = DCGANDiscriminator(args)\n",
    "# d(torch.rand(1, 3, 32, 32))\n",
    "criterion = DCGANLoss(args)\n",
    "criterion((torch.rand(1), torch.rand(1)), mode='generator_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17917da2-0af2-4693-81a0-7e9c77c06e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGANGenerator(\n",
       "  (net): Sequential(\n",
       "    (0): ConvTransposeBlock(\n",
       "      (deconv): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actv): ReLU()\n",
       "    )\n",
       "    (1): ConvTransposeBlock(\n",
       "      (deconv): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actv): ReLU()\n",
       "    )\n",
       "    (2): ConvTransposeBlock(\n",
       "      (deconv): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actv): ReLU()\n",
       "    )\n",
       "    (3): ConvTransposeBlock(\n",
       "      (deconv): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): Sequential()\n",
       "      (actv): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "533554c2-56e1-42f6-8ad8-b5be084c7685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-3.3361e-02,  4.7484e-03,  8.8337e-03, -4.2278e-02, -1.4795e-02,\n",
       "         1.5242e-02,  1.4019e-03, -7.7961e-03,  1.1149e-03, -6.3838e-03,\n",
       "         4.4132e-02,  1.6390e-02,  7.8639e-03, -3.3794e-03,  4.6303e-03,\n",
       "         6.1060e-03, -1.9545e-04, -3.9471e-03,  2.2000e-03, -9.4550e-03,\n",
       "         2.1371e-02, -1.9330e-02,  1.9404e-02, -1.4085e-03,  9.7211e-03,\n",
       "         7.1018e-04, -2.0313e-02,  5.4012e-03,  2.8326e-02, -3.5813e-02,\n",
       "        -2.5176e-02, -5.6153e-03, -4.2708e-03, -2.1380e-02, -5.4555e-03,\n",
       "         6.1231e-03, -2.1843e-02,  1.7375e-04,  4.2771e-03, -1.1101e-02,\n",
       "        -1.6016e-02,  2.2322e-02, -5.2337e-03,  8.3100e-03,  3.6959e-02,\n",
       "        -2.2778e-05, -1.5645e-02, -1.2547e-02, -4.2400e-03,  4.3271e-03,\n",
       "         2.5820e-02, -2.4466e-02, -6.3521e-03, -3.1910e-02,  1.6226e-02,\n",
       "        -4.7438e-04, -2.4821e-02, -4.8451e-02, -4.1103e-02, -1.2347e-02,\n",
       "        -5.0930e-03,  2.0740e-02,  3.0244e-04,  1.3278e-02, -2.3070e-04,\n",
       "        -7.1682e-03, -8.6342e-03,  9.1225e-03,  5.7849e-03, -2.0445e-02,\n",
       "         1.2926e-02,  1.4571e-02,  4.2816e-02,  3.1475e-02,  1.3438e-02,\n",
       "        -1.2005e-02, -1.9975e-02,  2.2040e-02,  2.6338e-02, -3.2729e-02,\n",
       "        -2.8800e-02,  1.2953e-02,  5.1749e-03, -8.9521e-03,  1.7993e-02,\n",
       "        -2.0269e-02, -4.0060e-03,  1.1593e-02, -2.9077e-02,  1.2608e-02,\n",
       "         6.1489e-03,  2.3284e-02,  9.7638e-03, -1.4495e-02, -1.7489e-02,\n",
       "         9.0951e-03,  9.3544e-03,  7.8662e-03, -1.2746e-02, -5.9584e-03,\n",
       "        -6.6942e-03,  4.3044e-03,  3.7683e-02, -1.4282e-03, -1.3649e-02,\n",
       "        -2.6915e-02, -2.3404e-02, -4.3919e-02,  4.1918e-03, -1.8284e-02,\n",
       "         2.5892e-02, -7.8061e-03, -2.8792e-03, -4.8987e-02,  6.6995e-03,\n",
       "         1.2615e-02, -1.2142e-02,  1.7333e-02, -6.3892e-03,  1.5923e-02,\n",
       "         4.1849e-02,  6.1127e-03, -5.5722e-03, -1.3654e-02,  3.4102e-02,\n",
       "         2.1612e-02,  8.4694e-03,  3.1956e-02, -1.6681e-02,  2.8321e-02,\n",
       "         5.2681e-03, -6.3555e-04, -2.4290e-03, -1.0262e-02, -1.0810e-02,\n",
       "        -2.1131e-02, -4.9446e-03, -4.8125e-02, -7.0963e-03,  1.9714e-02,\n",
       "         1.2567e-02,  9.5779e-03,  5.0014e-03,  2.3070e-02, -5.3712e-04,\n",
       "         2.2283e-02, -5.0471e-02, -3.1505e-02,  2.2861e-02,  2.8557e-02,\n",
       "        -2.9210e-02, -2.3225e-02,  5.2224e-03,  1.3353e-02,  2.4235e-02,\n",
       "        -4.4958e-03,  2.9554e-02, -2.7225e-03, -1.7253e-02, -1.6535e-02,\n",
       "         3.2254e-02,  1.5296e-02,  2.2054e-02, -2.7931e-02, -3.2039e-02,\n",
       "         2.3155e-02,  2.5633e-02, -3.0416e-02, -3.9873e-02, -1.7708e-03,\n",
       "        -8.9914e-03, -6.3648e-03,  1.1983e-02, -6.1506e-03, -5.8307e-03,\n",
       "        -2.3605e-02,  9.1211e-03,  8.2245e-03, -5.0907e-04, -1.6403e-02,\n",
       "         3.2520e-02,  3.1955e-02,  1.3396e-02,  1.8252e-02, -1.8048e-02,\n",
       "         9.3973e-03, -1.6760e-02,  1.8218e-03,  2.6090e-02, -2.3792e-02,\n",
       "         6.7823e-03,  5.1556e-03,  3.6058e-02, -2.4456e-02,  1.9804e-03,\n",
       "         1.7826e-02,  2.9330e-02, -2.7276e-03, -7.9420e-03, -3.3557e-03,\n",
       "        -7.2412e-03, -7.3746e-02,  8.0893e-03,  3.7082e-02, -5.1895e-04,\n",
       "        -9.4920e-03, -2.0050e-02, -3.3229e-03, -2.7469e-02, -2.2924e-02,\n",
       "        -1.7939e-02, -2.9878e-03,  2.5661e-02, -2.0932e-02,  9.6307e-03,\n",
       "         8.0108e-03,  3.4596e-02,  4.5111e-04, -6.9935e-03, -2.3983e-02,\n",
       "        -3.4849e-02,  1.6423e-02,  3.5005e-02, -3.3703e-03, -1.6358e-02,\n",
       "        -1.2217e-02, -2.5218e-02,  7.9376e-03, -4.9780e-03,  5.2763e-02,\n",
       "        -2.0141e-03,  3.2333e-02, -2.2627e-02,  3.4807e-03,  1.7219e-03,\n",
       "         1.8645e-02, -9.8431e-04, -1.0107e-02, -1.0421e-02,  2.8434e-02,\n",
       "        -2.8825e-02, -1.1809e-02, -1.9493e-02, -3.2134e-02, -2.0264e-02,\n",
       "         2.8216e-02,  1.9442e-02, -2.2041e-02,  1.7000e-02,  1.8911e-02,\n",
       "         2.4228e-02, -9.4229e-03,  6.9252e-04, -1.7661e-04, -4.3591e-02,\n",
       "         1.3775e-03], requires_grad=True)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.net[0].norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b27dbb-5760-40ec-b960-4c410452f445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
