{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f48938-34a5-4f48-a685-6738dea79152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# train\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import models\n",
    "\n",
    "from dataloader import get_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9bca27db-b7db-4648-b557-40c028b3ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "args = EasyDict({\n",
    "    'model_name': 'dcgan',\n",
    "    'dataset_name': 'cifar10',\n",
    "    'data_root': '../data/',\n",
    "    'resolution': 32,\n",
    "    'classes_to_include': [0], #[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'batch_size': 128,\n",
    "    'device': 'cuda',\n",
    "    'nz': 100,\n",
    "    'ngf': 64,\n",
    "    'ndf': 64,\n",
    "    'nc': 3,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f2a33-382f-4a6c-ab66-6256c71e695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Iteration: 1000\n",
      "Discriminator Loss: 0.4078954756259918\n",
      "Generator Loss: 1.654304027557373\n",
      "--------------------\n",
      "Iteration: 2000\n",
      "Discriminator Loss: 0.33238404989242554\n",
      "Generator Loss: 1.978642225265503\n",
      "--------------------\n",
      "Iteration: 3000\n",
      "Discriminator Loss: 0.2976579964160919\n",
      "Generator Loss: 1.9868347644805908\n",
      "--------------------\n",
      "Iteration: 4000\n",
      "Discriminator Loss: 0.28929203748703003\n",
      "Generator Loss: 2.0308284759521484\n",
      "--------------------\n",
      "Iteration: 5000\n",
      "Discriminator Loss: 0.3177807927131653\n",
      "Generator Loss: 2.748940944671631\n",
      "--------------------\n",
      "Iteration: 6000\n",
      "Discriminator Loss: 0.19926047325134277\n",
      "Generator Loss: 3.305755615234375\n",
      "--------------------\n",
      "Iteration: 7000\n",
      "Discriminator Loss: 0.17522764205932617\n",
      "Generator Loss: 3.7408151626586914\n",
      "--------------------\n",
      "Iteration: 8000\n",
      "Discriminator Loss: 0.10158485174179077\n",
      "Generator Loss: 3.0705204010009766\n"
     ]
    }
   ],
   "source": [
    "device = args.device\n",
    "\n",
    "tot_itr = 10000\n",
    "model_classes = [m for m in dir(models) \n",
    "                   if m.lower() == args.model_name.lower()]\n",
    "assert model_classes, f'Model name {args.model_name} does not exist'\n",
    "components = getattr(models, model_classes[0]).components\n",
    "\n",
    "generator = components['generator'](args).train().to(device)\n",
    "discriminator = components['discriminator'](args).train().to(device)\n",
    "criterion = components['criterion'](args)\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "losses_d, losses_g = [], []\n",
    "\n",
    "train_loader = get_dataloader(args, train=True)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "for itr in range(tot_itr):\n",
    "    try:\n",
    "        imgs, _ = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_loader = get_dataloader(args, train=True)\n",
    "        train_iter = iter(train_loader)\n",
    "        imgs, _ = next(train_iter)\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    # 1. Update Discriminator\n",
    "\n",
    "    optimizer_d.zero_grad()\n",
    "    real_pred = discriminator(imgs)\n",
    "\n",
    "    noise = torch.randn(args.batch_size, args.nz, 1, 1).to(device)\n",
    "    fake_imgs = generator(noise)\n",
    "    fake_pred = discriminator(fake_imgs.detach())\n",
    "    loss_d = criterion((fake_pred, real_pred), mode='discriminator_loss')\n",
    "    losses_d.append(loss_d.item())\n",
    "\n",
    "    loss_d.backward()\n",
    "    optimizer_d.step()\n",
    "\n",
    "    # 2. Update Generator\n",
    "    optimizer_g.zero_grad()\n",
    "    fake_pred = discriminator(fake_imgs)\n",
    "    loss_g = criterion((fake_pred, real_pred), mode='generator_loss')\n",
    "    losses_g.append(loss_g.item())\n",
    "\n",
    "    loss_g.backward()\n",
    "    optimizer_g.step()\n",
    "    \n",
    "    if (itr + 1) % int(tot_itr / 10) == 0:\n",
    "        print('-' * 20)\n",
    "        print(f'Iteration: {itr + 1}')\n",
    "        print(f'Discriminator Loss: {loss_d}')\n",
    "        print(f'Generator Loss: {loss_g}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439df49-1f8a-4b28-af32-1d30e2f83fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses_d)\n",
    "plt.plot(losses_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc77a3d-7c46-487d-a377-84300438be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imgs):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torchvision\n",
    "    imgs = torchvision.utils.make_grid(imgs)\n",
    "    plt.imshow(imgs.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983ef86-ba22-4afe-840b-4a8f94791756",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval().cpu()\n",
    "with torch.no_grad():\n",
    "    imgs = generator(torch.randn(1, args.nz, 1, 1))\n",
    "plot_images(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95a204e8-3480-4378-a366-d1ad5f576660",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-75-5e178223a5ec>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-75-5e178223a5ec>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    torch.save(ckpt, f'checkpoints/{args.model_name}.{datetime.now().strftime('%d%m%y.%H%M%S')}.pt')\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "discriminator.cpu()\n",
    "generator.train()\n",
    "ckpt = {\n",
    "    'generator': generator.state_dict(),\n",
    "    'discriminator': discriminator.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(ckpt, f'checkpoints/{args.model_name}.{datetime.now().strftime('%d%m%y.%H%M%S')}.pt')\n",
    "print(os.walk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571e0d38-518f-4e74-9038-40e10a079871",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0ce31d5eafc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('../data/')\n",
    "dataloader = DataLoader(dataset)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f91a21-7820-4393-878a-cf23f08d43c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
